{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2a7036",
   "metadata": {},
   "source": [
    "<span style=\"color:white\">MÉTODOS NUMÉRICOS</span>\n",
    "\n",
    "<span style=\"color:white\">COSTOS RELACIONADOS A MODELOS DE LENGUAJE</span>\n",
    "\n",
    "<span style=\"color:white\">Nombre: Alegria Isabel Farinango</span>\n",
    "\n",
    "<span style=\"color:white\">Indicaciones</span>\n",
    "\n",
    "<span style=\"color:white\">1. ¿Qué es inferencia y entrenamiento, cuál es la diferencia?</span>\n",
    "\n",
    "<span style=\"color:white\">El ciclo de vida de un modelo de IA se divide en dos fases con requerimientos de cómputo y energía diferentes.</span>\n",
    "\n",
    "<span style=\"color:white\">1.1. Entrenamiento (Training) : Proceso inicial y más intensivo en cómputo donde el modelo aprende de un vasto conjunto de datos (billones o trillones de tokens). Su objetivo es crear el modelo, ajustando sus miles de millones de parámetros para que pueda predecir el siguiente token con precisión.</span>\n",
    "\n",
    "<span style=\"color:whitek\">Requisitos de Hardware: Requiere la mayor cantidad de GPUs, a menudo miles, trabajando en paralelo en un clúster. Necesita GPUs con gran ancho de banda (como la H100) y grandes cantidades de RAM.</span>\n",
    "\n",
    "<span style=\"color:white\">Costo y Energía: Es la fase más cara y energéticamente demandante. Consume GWh de electricidad.</span>\n",
    "\n",
    "<span style=\"color:white\">Duración: Ocurre una sola vez y puede durar semanas o meses.</span>\n",
    "\n",
    "<span style=\"color:white\">1.2. Inferencia (Inference) : Proceso de usar el modelo entrenado para generar una respuesta a una consulta o prompt de un usuario, su objetivo es aplicar el conocimiento aprendido para generar una salida (texto, código, imagen, etc.)</span>\n",
    "\n",
    "<span style=\"color:white\">Requisitos de Hardware: Consume mucha menos potencia que el entrenamiento. Puede ejecutarse en una sola GPU o un pequeño grupo. El enfoque está en la eficiencia (obtener una respuesta rápida).</span>\n",
    "\n",
    "<span style=\"color:white\">Costo y Energía: Es la fase de mayor uso continuo. El costo y el consumo de energía por consulta individual son bajos ($Wh$), pero el costo total acumulado es inmenso debido a los miles de millones de consultas diarias.</span>\n",
    "\n",
    "<span style=\"color:white\">Duración: Ocurre cada vez que el modelo es consultado.</span>\n",
    "\n",
    "<span style=\"color:white\">2. Modelo de GPU utilizado/s</span>\n",
    "\n",
    "![Modelo](4.png)\n",
    "\n",
    "<span style=\"color:white\">3. Costo del hardware (costo GPU x número de GPUs) en inferencia y entrenamiento</span>\n",
    "\n",
    "![Costo](5.png) \n",
    "\n",
    "<span style=\"color:white\">5. Consumo energético (watts) en inferencia y entrenamiento.</span>\n",
    "\n",
    "![Costo](6.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
